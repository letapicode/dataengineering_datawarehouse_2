{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Data Warehouse Infrastructure Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identity and Access Management (IAM) Users Creation and Deletion: to manage access to AWS services and resources.\n",
    "2. IAM Roles Creation and Deletion: to delegate permissions to AWS services.\n",
    "3. Security Groups Creation and Deletion: to control inbound and outbound traffic to the AWS resources.\n",
    "4. Redshift Cluster Creation and Deletion: to store and manage the data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules and packages\n",
    "import boto3\n",
    "import configparser\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAM Users Creation and Deletion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code reads AWS credentials and configuration from the dwh.cfg file. If system_admin_key \n",
    "and system_admin_secret are provided in the configuration file, an IAM client is created using \n",
    "the 'system_admin' user's AWS credentials. Otherwise, an IAM client is created using the AWS \n",
    "credentials generated from the Launch Cloud Gateway.\n",
    "\"\"\"\n",
    "# Read the AWS credentials and configuration from the dwh.cfg file\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "try:\n",
    "    with open('dwh.cfg') as config_file:\n",
    "        config.read_file(config_file)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error reading configuration file: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "        \n",
    "# Get the AWS credentials from the dwh.cfg file    \n",
    "KEY = config.get('AWS', 'gateway_key')\n",
    "SECRET = config.get('AWS', 'gateway_secret')\n",
    "AWS_SESSION_TOKEN= config.get('AWS', 'gateway_aws_session_token')\n",
    "\n",
    "system_admin_key = config.get('AWS', 'system_admin_key')\n",
    "system_admin_secret = config.get('AWS', 'system_admin_secret') \n",
    "\n",
    "if system_admin_key and system_admin_secret:\n",
    "    # Create an IAM client using the AWS credentials generated by the 'system_admin' user \n",
    "    iam = boto3.client('iam',\n",
    "                      aws_access_key_id=system_admin_key,\n",
    "                      aws_secret_access_key=system_admin_secret)\n",
    "\n",
    "else:\n",
    "    # Create an IAM client using the AWS credentials generated from the Launch Cloud Gateway \n",
    "    iam = boto3.client('iam',\n",
    "                      aws_access_key_id=KEY,\n",
    "                      aws_secret_access_key=SECRET,\n",
    "                      aws_session_token=AWS_SESSION_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM user system_admin already exists\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following code creates an IAM user with AdministratorAccess policy and saves the user's \n",
    "access key ID and secret to the dwh.cfg configuration file.\n",
    "\n",
    "Raises:\n",
    "\n",
    "    -> FileNotFoundError: If the dwh.cfg file is not found.\n",
    "    -> configparser.NoSectionError: If the required section is missing from the dwh.cfg file.\n",
    "    -> configparser.NoOptionError: If the required option is missing from the dwh.cfg file.\n",
    "    -> iam.exceptions.NoSuchEntityException: If the IAM user does not exist.\n",
    "    -> Exception: If an error occurs while creating the IAM user or attaching policies to the user.\n",
    "    \n",
    "The code reads the AWS credentials and configuration from the dwh.cfg file using the \n",
    "configparser module. It then retrieves the name of the IAM user from the configuration file. \n",
    "If the IAM user already exists, the code prints a message indicating this. Otherwise, \n",
    "the code creates the IAM user with the AdministratorAccess policy, attaches the policy to the user, \n",
    "and creates access keys for the user. The access key ID and secret are then saved to the dwh.cfg file.\n",
    "\n",
    "Note that the iam client used in this code is assumed to have already been created earlier in the program.\n",
    "\"\"\"\n",
    "# Read the AWS credentials and configuration from the dwh.cfg file\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "try:\n",
    "    with open('dwh.cfg') as config_file:\n",
    "        config.read_file(config_file)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error reading configuration file: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "# Specify the IAM user name    \n",
    "try:\n",
    "    admin_username = config.get('AWS', 'admin_username')\n",
    "except configparser.NoSectionError:\n",
    "    print(\"Error: Configuration file is missing required section.\")\n",
    "    exit(1)\n",
    "except configparser.NoOptionError:\n",
    "    print(\"Error: Configuration file is missing required option.\")\n",
    "    exit(1)\n",
    "    \n",
    "# Create an IAM user with AdministratorAccess policy\n",
    "try:\n",
    "    # Check if the IAM user already exists\n",
    "    iam.get_user(UserName=admin_username)\n",
    "    print(f\"IAM user {admin_username} already exists\")\n",
    "# If the IAM user does not exist, create it\n",
    "except iam.exceptions.NoSuchEntityException:\n",
    "    try:\n",
    "        response = iam.create_user(UserName=admin_username)\n",
    "        print(f\"IAM user {admin_username} created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating IAM user: {str(e)}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Attach policies to the IAM user   \n",
    "    policy_arns = ['arn:aws:iam::aws:policy/AdministratorAccess', \n",
    "                   'arn:aws:iam::aws:policy/AmazonRedshiftFullAccess',\n",
    "                  'arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess']\n",
    "    \n",
    "    for arn in policy_arns:\n",
    "        try:\n",
    "            response = iam.attach_user_policy(UserName=admin_username, PolicyArn=arn)\n",
    "        except Exception as e:\n",
    "            print(f\"Error attaching IAM policy: {str(e)}\")\n",
    "            exit(1)\n",
    "\n",
    "    # Create access keys for the IAM user\n",
    "    try:\n",
    "        access_key = iam.create_access_key(UserName=admin_username)['AccessKey']\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating IAM access key: {str(e)}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Save the new access key ID and secret in your dwh.cfg file\n",
    "    config.set('AWS', 'system_admin_key', access_key['AccessKeyId'])\n",
    "    config.set('AWS', 'system_admin_secret', access_key['SecretAccessKey'])\n",
    "\n",
    "    with open('dwh.cfg', 'w') as config_file:\n",
    "        config.write(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User deletion skipped...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To delete a user along with their secret key and policies, set the 'delete_user' flag to True \n",
    "and ensure that the 'delete_username' matches the username of the user to be deleted.\n",
    "\n",
    "This code performs the deletion of an IAM user from AWS, along with their associated \n",
    "policies and access key. The user to be deleted is specified using the variable delete_username. \n",
    "The access key is retrieved from the dwh.cfg configuration file based on whether the user to be deleted \n",
    "is the data_engineer_username or system_admin_username.\n",
    "\n",
    "If the delete_user flag is set to True, the access key associated with the specified user is deleted first. \n",
    "Then, all policies attached to the user are detached, and the user is deleted. If the user to be deleted is \n",
    "the system_admin_username, the system_admin_key and system_admin_secret values in the dwh.cfg configuration \n",
    "file are set to empty strings. If the user to be deleted is the data_engineer_username, the data_engineer_key \n",
    "and data_engineer_secret values in the dwh.cfg configuration file are set to empty strings. Finally, \n",
    "the updated dwh.cfg configuration file is written back to disk.\n",
    "\n",
    "The code includes a try-except block to handle situations where the dwh.cfg file is not found. \n",
    "If an exception is raised, the script will print an error message and exit with a status of 1.\n",
    "\"\"\"\n",
    "# Read the AWS credentials and configuration from the dwh.cfg file\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "try:\n",
    "    with open('dwh.cfg') as config_file:\n",
    "        config.read_file(config_file)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error reading configuration file: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "delete_username = admin_username\n",
    "\n",
    "delete_user = False\n",
    "\n",
    "if delete_user:\n",
    "    if delete_username == admin_username:\n",
    "        access_key = config.get('AWS', 'system_admin_key')\n",
    "        \n",
    "    # Delete the access key\n",
    "    try:\n",
    "        iam.delete_access_key(\n",
    "            AccessKeyId=access_key,\n",
    "            UserName=delete_username\n",
    "        )\n",
    "    except iam.exceptions.NoSuchEntityException:\n",
    "        print(\"Access key does not exist for user:\", delete_username)\n",
    "\n",
    "    # Detach all policies from the user\n",
    "    attached_policies = iam.list_attached_user_policies(UserName=delete_username)\n",
    "    for policy in attached_policies['AttachedPolicies']:\n",
    "        try:\n",
    "            iam.detach_user_policy(UserName=delete_username, PolicyArn=policy['PolicyArn'])\n",
    "        except iam.exceptions.NoSuchEntityException:\n",
    "            print(\"Policy does not exist for user:\", delete_username)\n",
    "\n",
    "    # Delete the user\n",
    "    try:\n",
    "        iam.delete_user(\n",
    "            UserName=delete_username\n",
    "        )\n",
    "    except iam.exceptions.NoSuchEntityException:\n",
    "        print(\"User does not exist:\", delete_username)\n",
    "    \n",
    "    if delete_username == admin_username:\n",
    "        print(f\"User: {delete_username} deleted...\")\n",
    "        # Remove the access key ID and secret in your dwh.cfg file\n",
    "        config.set('AWS', 'system_admin_key', '')\n",
    "        config.set('AWS', 'system_admin_secret', '')\n",
    "\n",
    "    with open('dwh.cfg', 'w') as config_file:\n",
    "        config.write(config_file)\n",
    "else:\n",
    "    print(\"User deletion skipped...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAM Roles Creation and Deletion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the system admin key and secret, which was set up with administrative access\n",
    "KEY                    = config.get('AWS','system_admin_key')\n",
    "SECRET                 = config.get('AWS','system_admin_secret')\n",
    "\n",
    "# Create an IAM client with the provided credentials\n",
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name='us-east-1'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IAM Role 'myDataWarehouseRedshiftRole' already exists.\n",
      "Arn:  arn:aws:iam::065061674598:role/myDataWarehouseRedshiftRole\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code creates an AWS IAM role with a specified name and attaches an Amazon S3 \n",
    "policy to it. If the role already exists, the code retrieves its ARN. \n",
    "The ARN is then saved to a configuration file.\n",
    "\"\"\"\n",
    "# Define the IAM role name\n",
    "role_name = 'myDataWarehouseRedshiftRole'\n",
    "\n",
    "# Define the policy ARN to attach to the role\n",
    "policy_arn = 'arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'\n",
    "\n",
    "# Create the role if it doesn't exist\n",
    "try:\n",
    "    role = iam.get_role(RoleName=role_name)\n",
    "    roleArn = role['Role']['Arn']\n",
    "    print(f\"The IAM Role '{role_name}' already exists.\")\n",
    "    \n",
    "except iam.exceptions.NoSuchEntityException:\n",
    "    # Create the role if it doesn't exist\n",
    "    try:\n",
    "        print(f\"Creating a new IAM Role '{role_name}'\")\n",
    "        dwhRole = iam.create_role(\n",
    "            Path='/',\n",
    "            RoleName=role_name,\n",
    "            Description=\"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "            AssumeRolePolicyDocument=json.dumps({\n",
    "                'Statement': [{\n",
    "                    'Action': 'sts:AssumeRole',\n",
    "                    'Effect': 'Allow',\n",
    "                    'Principal': {'Service': 'redshift.amazonaws.com'}\n",
    "                }],\n",
    "                'Version': '2012-10-17'\n",
    "            })\n",
    "        )\n",
    "         \n",
    "        # Attach the policy to the role\n",
    "        iam.attach_role_policy(RoleName=role_name, PolicyArn=policy_arn)\n",
    "        print(f\"The IAM Role '{role_name}' was created successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating the IAM Role: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Get the IAM role ARN\n",
    "roleArn = iam.get_role(RoleName=role_name)['Role']['Arn']\n",
    "\n",
    "print(\"Arn: \", roleArn)\n",
    "# Save the new IAM role ARN in the dwh.cfg file\n",
    "config.set('IAM_ROLE', 'arn', roleArn)\n",
    "\n",
    "with open('dwh.cfg', 'w') as config_file:\n",
    "    config.write(config_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM role deletion skipped...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To delete the I AM role with policies, set the 'delete_role' flag to True \n",
    "and make sure the 'delete_role_name' is correct.\n",
    "\n",
    "Delete an IAM role with a specified name. If the delete_role flag is set to True, \n",
    "detach all policies from the role and delete the role. If the role doesn't exist, \n",
    "notify the user.\n",
    "\"\"\"\n",
    "\n",
    "delete_role = False\n",
    "\n",
    "if delete_role:\n",
    "    # Define the name of the role to delete\n",
    "    delete_role_name = 'myDataWarehouseRedshiftRole'\n",
    "\n",
    "    try:\n",
    "        # Check if the role exists\n",
    "        role = iam.get_role(RoleName=delete_role_name)\n",
    "\n",
    "        # Detach all policies from the role\n",
    "        response = iam.list_attached_role_policies(RoleName=delete_role_name)\n",
    "        for policy in response['AttachedPolicies']:\n",
    "            iam.detach_role_policy(RoleName=delete_role_name, PolicyArn=policy['PolicyArn'])\n",
    "\n",
    "        # Delete the role\n",
    "        iam.delete_role(RoleName=delete_role_name)\n",
    "\n",
    "        print(f\"The IAM Role '{delete_role_name}' was successfully deleted.\")\n",
    "        \n",
    "    except iam.exceptions.NoSuchEntityException:\n",
    "        print(f\"The IAM Role '{delete_role_name}' does not exist.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deleting the IAM Role: {e}\")\n",
    "        raise e\n",
    "else:\n",
    "    print(\"IAM role deletion skipped...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security Groups Creation and Deletion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security group 'redshift_security_group' already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code creates a security group in AWS EC2 for a Redshift cluster with TCP port 5439 open \n",
    "to all IP addresses. It first checks if the security group exists, and if not, it creates a \n",
    "new one and adds the required inbound rule. The system admin key and secret are used \n",
    "for authentication.\n",
    "\"\"\"\n",
    "\n",
    "# Use the system admin key and secret, which was set up with administrative access\n",
    "KEY                    = config.get('AWS','system_admin_key')\n",
    "SECRET                 = config.get('AWS','system_admin_secret')\n",
    "\n",
    "# Create an ec2 client with the provided credentials\n",
    "ec2 = boto3.client('ec2',\n",
    "                   region_name=\"us-east-1\",\n",
    "                   aws_access_key_id=KEY,\n",
    "                   aws_secret_access_key=SECRET)\n",
    "\n",
    "security_group_name = 'redshift_security_group'\n",
    "\n",
    "create_security_group = True\n",
    "\n",
    "if create_security_group:\n",
    "    try:\n",
    "        # Check if security group with the given name already exists\n",
    "        response = ec2.describe_security_groups(GroupNames=[security_group_name])\n",
    "        \n",
    "        # If the security group exists, don't create a new one\n",
    "        if response['SecurityGroups']:\n",
    "            print(f\"Security group '{security_group_name}' already exists. Skipping creation.\")\n",
    "            security_group_id = response['SecurityGroups'][0]['GroupId']\n",
    "  \n",
    "    # If the security group doesn't exist, create a new one\n",
    "    except ClientError as e:\n",
    "        # Security group does not exist, create it and authorize ingress\n",
    "        if e.response['Error']['Code'] == 'InvalidGroup.NotFound':\n",
    "            # Filter the default VPC in the EC2 service and retrieve its ID\n",
    "            response = ec2.describe_vpcs(Filters=[{'Name': 'isDefault','Values': ['true']}])\n",
    "            vpc_id = response['Vpcs'][0]['VpcId']\n",
    "\n",
    "            # Create a security group\n",
    "            security_group = ec2.create_security_group(\n",
    "                GroupName=security_group_name,\n",
    "                Description='Authorise redshift cluster access',\n",
    "                VpcId=vpc_id\n",
    "            )\n",
    "\n",
    "            # Get the security group ID\n",
    "            security_group_id = security_group['GroupId']\n",
    "\n",
    "            # Authorize ingress on the security group\n",
    "            response = ec2.authorize_security_group_ingress(\n",
    "                GroupId=security_group_id,\n",
    "                IpPermissions=[\n",
    "                    {\n",
    "                        'IpProtocol': 'tcp',\n",
    "                        'FromPort': 5439,\n",
    "                        'ToPort': 5439,\n",
    "                        'IpRanges': [\n",
    "                            {'CidrIp': '0.0.0.0/0'}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            print(f\"Security group '{security_group_name}' created with ID {security_group_id}.\")\n",
    "        else:\n",
    "            # Some other error occurred\n",
    "            print(\"Unexpected error:\", e)\n",
    "else:\n",
    "    print(\"Security group creation skipped...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security group deletion skipped...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code checks if a security group exists and deletes it if it does. If the security group \n",
    "doesn't exist, it prints a message. The deletion is controlled by a boolean flag.\n",
    "\"\"\"\n",
    "\n",
    "delete_security_group_name = 'redshift_security_group'\n",
    "\n",
    "delete_security = False\n",
    "\n",
    "if delete_security:\n",
    "    try:\n",
    "        # Check if security group with the given name already exists\n",
    "        response = ec2.describe_security_groups(GroupNames=[delete_security_group_name])\n",
    "\n",
    "        # If the security group exists, delete it\n",
    "        if response['SecurityGroups']:\n",
    "            security_group_id = response['SecurityGroups'][0]['GroupId']\n",
    "            ec2.delete_security_group(GroupId=security_group_id)\n",
    "            print(f\"Security group '{delete_security_group_name}' with ID {security_group_id} deleted.\")\n",
    "\n",
    "    # If the security group doesn't exist, don't do anything\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'InvalidGroup.NotFound':\n",
    "            print(f\"Security group '{delete_security_group_name}' does not exist. Skipping deletion.\")\n",
    "        else:\n",
    "            # Some other error occurred\n",
    "            print(\"Unexpected error:\", e)\n",
    "\n",
    "else:\n",
    "    print(\"Security group deletion skipped...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Clusters Creation and Deletion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read configuration values from a configuration file 'dwh.cfg' and create a Redshift \n",
    "client using Boto3 library.\n",
    "\n",
    "Attributes:\n",
    "\n",
    "DWH_CLUSTER_TYPE: string value for the type of Redshift cluster.\n",
    "DWH_NODE_TYPE: string value for the node type of Redshift cluster.\n",
    "DWH_NUM_NODES: integer value for the number of nodes in the Redshift cluster.\n",
    "DWH_DB: string value for the name of the Redshift database.\n",
    "DWH_CLUSTER_IDENTIFIER: string value for the identifier of the Redshift cluster.\n",
    "DWH_DB_USER: string value for the user name to connect to the Redshift cluster.\n",
    "DWH_DB_PASSWORD: string value for the password to connect to the Redshift cluster.\n",
    "DWH_PORT: integer value for the port number of the Redshift cluster.\n",
    "DWH_SUBNET_GROUP_NAME: string value for the name of the subnet group of the Redshift cluster.\n",
    "DWH_REDSHIFT_SECURITY_GROUP: string value for the name of the security group of the Redshift cluster.\n",
    "roleArn: string value for the Amazon Resource Name (ARN) of the IAM role.\n",
    "KEY: string value for the system administrator key for AWS.\n",
    "SECRET: string value for the system administrator secret for AWS.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with open('dwh.cfg') as config_file:\n",
    "        config.read_file(config_file)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error reading configuration file: {str(e)}\")\n",
    "    exit(1)\n",
    "    \n",
    "# Get the configuration values\n",
    "try:\n",
    "    DWH_CLUSTER_TYPE                 = config.get('DWH','dwh_cluster_type')\n",
    "    DWH_NODE_TYPE                    = config.get('DWH','dwh_node_type')\n",
    "    DWH_NUM_NODES                    = int(config.get('DWH','dwh_num_nodes'))\n",
    "    DWH_DB                           = config.get('DWH','dwh_db')\n",
    "    DWH_CLUSTER_IDENTIFIER           = config.get('DWH','dwh_cluster_identifier')\n",
    "    DWH_DB_USER                      = config.get('DWH','dwh_db_user')\n",
    "    DWH_DB_PASSWORD                  = config.get('DWH','dwh_db_password')\n",
    "    DWH_PORT                         = int(config.get('DWH','dwh_port'))\n",
    "    DWH_SUBNET_GROUP_NAME            = config.get('DWH','dwh_subnet_group_name')\n",
    "    DWH_REDSHIFT_SECURITY_GROUP      = config.get('DWH','dwh_redshift_security_group_name')\n",
    "    \n",
    "    roleArn                 = config.get('IAM_ROLE','arn')\n",
    "    \n",
    "    KEY                     = config.get('AWS','system_admin_key')\n",
    "    SECRET                  = config.get('AWS','system_admin_secret')\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"Missing configuration value: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# Create a Redshift client\n",
    "try:\n",
    "    redshift = boto3.client('redshift',\n",
    "                           region_name=\"us-east-1\",\n",
    "                           aws_access_key_id=KEY,\n",
    "                           aws_secret_access_key=SECRET\n",
    "                           )\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create Redshift client: {e}\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataWarehouseRedshiftCluster\n"
     ]
    }
   ],
   "source": [
    "print(DWH_CLUSTER_IDENTIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 security group(s) with name redshift_security_group\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code retrieves security groups with the specified name of 'redshift_security_group' and extracts\n",
    "their IDs from the response. \n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # retrieve the security groups with the specified name of 'redshift_security_group'\n",
    "    response = ec2.describe_security_groups(Filters=[{'Name': 'group-name','Values': [DWH_REDSHIFT_SECURITY_GROUP]}])\n",
    "\n",
    "    if 'SecurityGroups' in response:\n",
    "        # extract the security group IDs from the response\n",
    "        security_group_ids = [sg['GroupId'] for sg in response['SecurityGroups']]\n",
    "        print(f\"Found {len(security_group_ids)} security group(s) with name {DWH_REDSHIFT_SECURITY_GROUP}\")\n",
    "    else:\n",
    "        print(f\"No security groups found with name {DWH_REDSHIFT_SECURITY_GROUP}\")\n",
    "        security_group_ids = []\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving security groups: {e}\")\n",
    "    security_group_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Redshift cluster 'dataWarehouseRedshiftCluster' is being created...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Waiting for Redshift cluster 'dataWarehouseRedshiftCluster' to become available...\n",
      "INFO:root:Redshift cluster 'dataWarehouseRedshiftCluster' has been successfully created and is available.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "This script provides functions for creating and managing Amazon Redshift clusters. It includes a function\n",
    "to check if a cluster exists, create a new cluster, and wait for it to become available. It requires the \n",
    "'boto3' and 'logging' modules to be installed and the cluster configuration to be specified \n",
    "in the calling script. If the 'should_create_cluster' flag is True, the script creates the cluster.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set the flag to control whether to create the cluster or not\n",
    "should_create_cluster = True\n",
    "\n",
    "# Function to check if a Redshift cluster exists\n",
    "def check_cluster_exists(redshift, cluster_identifier):\n",
    "    try:\n",
    "        response = redshift.describe_clusters(ClusterIdentifier=cluster_identifier)\n",
    "        cluster = response['Clusters'][0]\n",
    "        return True if cluster['ClusterIdentifier'] == cluster_identifier else False\n",
    "    except redshift.exceptions.ClusterNotFoundFault:\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error checking Redshift cluster {cluster_identifier}: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# Function to create a new Redshift cluster\n",
    "def create_cluster(redshift, cluster_config, role_arn, security_group_ids):\n",
    "    try:\n",
    "        response = redshift.create_cluster(\n",
    "            ClusterType=cluster_config['type'],\n",
    "            NodeType=cluster_config['node_type'],\n",
    "            NumberOfNodes=cluster_config['num_nodes'],\n",
    "            DBName=cluster_config['db_name'],\n",
    "            ClusterIdentifier=cluster_config['identifier'],\n",
    "            MasterUsername=cluster_config['user'],\n",
    "            MasterUserPassword=cluster_config['password'],\n",
    "            IamRoles=[role_arn],\n",
    "            VpcSecurityGroupIds=security_group_ids,\n",
    "            PubliclyAccessible=True,\n",
    "            Port=cluster_config['port']\n",
    "        )\n",
    "        logging.info(f\"Redshift cluster '{cluster_config['identifier']}' is being created...\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating Redshift cluster '{cluster_config['identifier']}': {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# Function to wait until the cluster becomes available\n",
    "def wait_cluster_available(redshift, cluster_identifier):\n",
    "    while True:\n",
    "        time.sleep(10)  # Wait for 10 seconds before checking the cluster status again\n",
    "        response = redshift.describe_clusters(ClusterIdentifier=cluster_identifier)\n",
    "        cluster = response['Clusters'][0]\n",
    "        if cluster['ClusterStatus'] == 'available':\n",
    "            break\n",
    "        logging.info(f\"Waiting for Redshift cluster '{cluster_identifier}' to become available...\")\n",
    "\n",
    "# Main script\n",
    "if should_create_cluster:\n",
    "    if not check_cluster_exists(redshift, DWH_CLUSTER_IDENTIFIER):\n",
    "        cluster_config = {\n",
    "            'type': DWH_CLUSTER_TYPE,\n",
    "            'node_type': DWH_NODE_TYPE,\n",
    "            'num_nodes': DWH_NUM_NODES,\n",
    "            'db_name': DWH_DB,\n",
    "            'identifier': DWH_CLUSTER_IDENTIFIER,\n",
    "            'user': DWH_DB_USER,\n",
    "            'password': DWH_DB_PASSWORD,\n",
    "            'port': DWH_PORT\n",
    "        }\n",
    "        create_cluster(redshift, cluster_config, roleArn, security_group_ids)\n",
    "        wait_cluster_available(redshift, DWH_CLUSTER_IDENTIFIER)\n",
    "        logging.info(f\"Redshift cluster '{DWH_CLUSTER_IDENTIFIER}' has been successfully created and is available.\")\n",
    "    else:\n",
    "        logging.info(f\"Redshift cluster '{DWH_CLUSTER_IDENTIFIER}' already exists. Skipping creation.\")\n",
    "else:\n",
    "    logging.info(\"Redshift cluster creation skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host:  datawarehouseredshiftcluster.c8mixlfqn1ra.us-east-1.redshift.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code reads the AWS Redshift cluster details from a configuration file, updates \n",
    "the host address with the cluster's endpoint, and writes the updated configuration back to the file. \n",
    "The endpoint address is also printed for verification.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "# Get cluster properties\n",
    "cluster_props = redshift.describe_clusters(ClusterIdentifier=config.get('DWH','DWH_CLUSTER_IDENTIFIER'))['Clusters'][0]\n",
    "\n",
    "# Get cluster endpoint\n",
    "host = cluster_props['Endpoint']['Address']\n",
    "\n",
    "# Update config file with host\n",
    "config.set('CLUSTER', 'host', host)\n",
    "\n",
    "# Write changes to config file\n",
    "with open('dwh.cfg', 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "\n",
    "# Print host for verification\n",
    "print(\"Host: \", host)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift cluster deletion skipped...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script deletes an Amazon Redshift cluster. It requires the 'boto3' module to be installed \n",
    "and the cluster identifier to be specified in the 'CLUSTER_IDENTIFIER' constant. If 'delete_cluster' \n",
    "is True, the script checks if the cluster exists, deletes it, and waits for it to be deleted. \n",
    "If the cluster does not exist, the script prints a message and exits. If 'delete_cluster' is False, \n",
    "the script prints a message and skips the deletion.\n",
    "\n",
    "\"\"\"\n",
    "# Set the cluster identifier for the cluster to be deleted\n",
    "CLUSTER_IDENTIFIER = DWH_CLUSTER_IDENTIFIER\n",
    "\n",
    "delete_cluster = False\n",
    "\n",
    "if delete_cluster:\n",
    "    # Check if the cluster exists\n",
    "    try:\n",
    "        response = redshift.describe_clusters(ClusterIdentifier=CLUSTER_IDENTIFIER)\n",
    "        cluster = response['Clusters'][0]\n",
    "        if cluster['ClusterIdentifier'] == CLUSTER_IDENTIFIER:\n",
    "            # Try to delete the cluster\n",
    "            try:\n",
    "                response = redshift.delete_cluster(\n",
    "                    ClusterIdentifier=CLUSTER_IDENTIFIER,\n",
    "                    SkipFinalClusterSnapshot=True\n",
    "                )\n",
    "                print(f\"Redshift cluster {CLUSTER_IDENTIFIER} is being deleted...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting redshift cluster {CLUSTER_IDENTIFIER}\")\n",
    "                exit(1)\n",
    "\n",
    "            # Wait for the cluster to be deleted\n",
    "            print(\"Waiting for the cluster to be deleted...\")\n",
    "            while True:\n",
    "                try:\n",
    "                    response = redshift.describe_clusters(ClusterIdentifier=CLUSTER_IDENTIFIER)\n",
    "                    cluster = response['Clusters'][0]\n",
    "                    if cluster['ClusterStatus'] == 'deleting':\n",
    "                        # Display the waiting animation while the cluster is being deleted\n",
    "                        for i in range(10):\n",
    "                            clear_output(wait=True)\n",
    "                            print(\"Waiting for the cluster to be deleted\" + \".\" * i)\n",
    "                            sleep(0.1)\n",
    "                    else:\n",
    "                        print(f\"Redshift cluster {CLUSTER_IDENTIFIER} has been successfully deleted.\")\n",
    "                        break\n",
    "                except redshift.exceptions.ClusterNotFoundFault:\n",
    "                    print(f\"Redshift cluster {CLUSTER_IDENTIFIER} has been successfully deleted.\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error checking redshift cluster {CLUSTER_IDENTIFIER}: {e}\")\n",
    "                    exit(1)\n",
    "    except redshift.exceptions.ClusterNotFoundFault:\n",
    "        print(f\"Redshift cluster {CLUSTER_IDENTIFIER} not found.\")\n",
    "        exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking redshift cluster {CLUSTER_IDENTIFIER}: {e}\")\n",
    "        exit(1)\n",
    "else:\n",
    "    print(\"Redshift cluster deletion skipped...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the create_tables.py file...\n",
      "DROP TABLE IF EXISTS staging_events;\n",
      "DROP TABLE IF EXISTS staging_songs;\n",
      "DROP TABLE IF EXISTS songplays;\n",
      "DROP TABLE IF EXISTS users;\n",
      "DROP TABLE IF EXISTS songs;\n",
      "DROP TABLE IF EXISTS artists;\n",
      "DROP TABLE IF EXISTS time;\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS staging_events (\n",
      "    artist          VARCHAR,\n",
      "    auth            VARCHAR,\n",
      "    firstName       VARCHAR,\n",
      "    gender          VARCHAR,\n",
      "    itemInSession   INTEGER,\n",
      "    lastName        VARCHAR,\n",
      "    length          FLOAT,\n",
      "    level           VARCHAR,\n",
      "    location        VARCHAR,\n",
      "    method          VARCHAR,\n",
      "    page            VARCHAR,\n",
      "    registration    BIGINT,\n",
      "    sessionId       INTEGER,\n",
      "    song            VARCHAR,\n",
      "    status          INTEGER,\n",
      "    ts              BIGINT,\n",
      "    userAgent       VARCHAR,\n",
      "    userId          INTEGER\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS staging_songs (\n",
      "    song_id         VARCHAR,\n",
      "    num_songs       INTEGER,\n",
      "    title           VARCHAR,\n",
      "    artist_name     VARCHAR,\n",
      "    artist_latitude FLOAT,\n",
      "    year            INTEGER,\n",
      "    duration        FLOAT,\n",
      "    artist_id       VARCHAR,\n",
      "    artist_longitude FLOAT,\n",
      "    artist_location VARCHAR\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS songplays (\n",
      "    songplay_id     INTEGER IDENTITY(0,1) PRIMARY KEY,\n",
      "    start_time      TIMESTAMP NOT NULL,\n",
      "    user_id         INTEGER NOT NULL,\n",
      "    level           VARCHAR,\n",
      "    song_id         VARCHAR,\n",
      "    artist_id       VARCHAR,\n",
      "    session_id      INTEGER,\n",
      "    location        VARCHAR,\n",
      "    user_agent      VARCHAR\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS users (\n",
      "    user_id         INTEGER PRIMARY KEY,\n",
      "    first_name      VARCHAR,\n",
      "    last_name       VARCHAR,\n",
      "    gender          VARCHAR,\n",
      "    level           VARCHAR\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS songs (\n",
      "    song_id         VARCHAR PRIMARY KEY,\n",
      "    title           VARCHAR,\n",
      "    artist_id       VARCHAR,\n",
      "    year            INTEGER,\n",
      "    duration        FLOAT\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS artists (\n",
      "    artist_id       VARCHAR PRIMARY KEY,\n",
      "    name            VARCHAR,\n",
      "    location        VARCHAR,\n",
      "    latitude        FLOAT,\n",
      "    longitude       FLOAT\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS time (\n",
      "    start_time      TIMESTAMP PRIMARY KEY,\n",
      "    hour            INTEGER,\n",
      "    day             INTEGER,\n",
      "    week            INTEGER,\n",
      "    month           INTEGER,\n",
      "    year            INTEGER,\n",
      "    weekday         INTEGER\n",
      ");\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the etl.py file...\n",
      "\n",
      "COPY staging_events \n",
      "FROM 's3://udacity-dend/log_data'\n",
      "CREDENTIALS 'aws_iam_role=arn:aws:iam::065061674598:role/myDataWarehouseRedshiftRole'\n",
      "REGION 'us-west-2'\n",
      "FORMAT AS JSON 's3://udacity-dend/log_json_path.json';\n",
      "\n",
      "\n",
      "COPY staging_songs \n",
      "FROM 's3://udacity-dend/song_data'\n",
      "CREDENTIALS 'aws_iam_role=arn:aws:iam::065061674598:role/myDataWarehouseRedshiftRole'\n",
      "REGION 'us-west-2'\n",
      "FORMAT AS JSON 'auto';\n",
      "\n",
      "\n",
      "INSERT INTO songplays (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
      "SELECT\n",
      "    TIMESTAMP 'epoch' + (e.ts / 1000) * INTERVAL '1 second' AS start_time,\n",
      "    e.userId AS user_id,\n",
      "    e.level,\n",
      "    s.song_id,\n",
      "    s.artist_id,\n",
      "    e.sessionId AS session_id,\n",
      "    e.location,\n",
      "    e.userAgent AS user_agent\n",
      "FROM staging_events e\n",
      "JOIN staging_songs s ON e.song = s.title AND e.artist = s.artist_name AND e.length = s.duration\n",
      "WHERE e.page = 'NextSong' AND e.userId IS NOT NULL;\n",
      "\n",
      "\n",
      "INSERT INTO users (user_id, first_name, last_name, gender, level)\n",
      "SELECT DISTINCT userId, firstName, lastName, gender, level\n",
      "FROM staging_events\n",
      "WHERE userId IS NOT NULL AND page = 'NextSong';\n",
      "\n",
      "\n",
      "INSERT INTO songs (song_id, title, artist_id, year, duration)\n",
      "SELECT DISTINCT song_id, title, artist_id, year, duration\n",
      "FROM staging_songs;\n",
      "\n",
      "\n",
      "INSERT INTO artists (artist_id, name, location, latitude, longitude)\n",
      "SELECT DISTINCT artist_id, artist_name, artist_location, artist_latitude, artist_longitude\n",
      "FROM staging_songs;\n",
      "\n",
      "\n",
      "INSERT INTO time (start_time, hour, day, week, month, year, weekday)\n",
      "SELECT\n",
      "    start_time,\n",
      "    EXTRACT(HOUR FROM start_time) AS hour,\n",
      "    EXTRACT(DAY FROM start_time) AS day,\n",
      "    EXTRACT(WEEK FROM start_time) AS week,\n",
      "    EXTRACT(MONTH FROM start_time) AS month,\n",
      "    EXTRACT(YEAR FROM start_time) AS year,\n",
      "    EXTRACT(WEEKDAY FROM start_time) AS weekday\n",
      "FROM songplays;\n",
      "\n",
      "\n",
      "    SELECT COUNT(*) FROM staging_events\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cut' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/workspace/home/etl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/home/etl.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{result}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cut' is not defined"
     ]
    }
   ],
   "source": [
    "%run etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the etl.py file...\n",
      "The number of records in each table: \n",
      "\n",
      "    SELECT COUNT(*) FROM staging_events\n",
      "\n",
      "(8056,)\n",
      "\n",
      "\n",
      "\n",
      "    SELECT COUNT(*) FROM staging_songs\n",
      "\n",
      "(14896,)\n",
      "\n",
      "\n",
      "\n",
      "    SELECT COUNT(*) FROM songplays\n",
      "\n",
      "(319,)\n",
      "\n",
      "\n",
      "\n",
      "    SELECT COUNT(*) FROM users\n",
      "\n",
      "(104,)\n",
      "\n",
      "\n",
      "\n",
      "    SELECT COUNT(*) FROM songs\n",
      "\n",
      "(14896,)\n",
      "\n",
      "\n",
      "\n",
      "    SELECT COUNT(*) FROM artists\n",
      "\n",
      "(10025,)\n",
      "\n",
      "\n",
      "\n",
      "    SELECT COUNT(*) FROM time\n",
      "\n",
      "(319,)\n",
      "\n",
      "\n",
      "\n",
      "SELECT s.title, a.name, COUNT(*) as play_count\n",
      "FROM songplays sp\n",
      "JOIN songs s ON sp.song_id = s.song_id\n",
      "JOIN artists a ON sp.artist_id = a.artist_id\n",
      "GROUP BY s.title, a.name\n",
      "ORDER BY play_count DESC\n",
      "LIMIT 10;\n",
      "\n",
      "most_played_songs_query selects the top 10 most played songs:\n",
      "\n",
      "(song title, artists name, play count): \n",
      "\n",
      "(\"You're The One\", 'Dwight Yoakam', 37)\n",
      "('Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', 'Lonnie Gordon', 9)\n",
      "(\"I CAN'T GET STARTED\", 'Ron Carter', 9)\n",
      "(\"Nothin' On You [feat. Bruno Mars] (Album Version)\", 'B.o.B', 8)\n",
      "(\"Hey Daddy (Daddy's Home)\", 'Usher featuring Jermaine Dupri', 6)\n",
      "(\"Hey Daddy (Daddy's Home)\", 'Usher', 6)\n",
      "('Up Up & Away', 'Kid Cudi', 5)\n",
      "('Make Her Say', 'Kid Cudi / Kanye West / Common', 5)\n",
      "('Up Up & Away', 'Kid Cudi / Kanye West / Common', 5)\n",
      "('Make Her Say', 'Kid Cudi', 5)\n",
      "\n",
      "\n",
      "\n",
      "SELECT t.hour, COUNT(*) as play_count\n",
      "FROM songplays sp\n",
      "JOIN time t ON sp.start_time = t.start_time\n",
      "GROUP BY t.hour\n",
      "ORDER BY play_count DESC;\n",
      "\n",
      "The peak_usage_hours_query selects the most popular hours for song plays: \n",
      "\n",
      "(hour, song play count):\n",
      "\n",
      "(17, 39)\n",
      "(18, 25)\n",
      "(15, 25)\n",
      "(16, 22)\n",
      "(8, 18)\n",
      "(20, 16)\n",
      "(11, 16)\n",
      "(14, 15)\n",
      "(13, 14)\n",
      "(7, 13)\n",
      "(19, 13)\n",
      "(12, 12)\n",
      "(21, 12)\n",
      "(23, 11)\n",
      "(10, 11)\n",
      "(1, 10)\n",
      "(6, 9)\n",
      "(9, 9)\n",
      "(5, 7)\n",
      "(22, 7)\n",
      "(4, 6)\n",
      "(0, 5)\n",
      "(2, 2)\n",
      "(3, 2)\n",
      "\n",
      "\n",
      "\n",
      "SELECT u.gender, u.level, COUNT(DISTINCT u.user_id) as user_count\n",
      "FROM songplays sp\n",
      "JOIN users u ON sp.user_id = u.user_id\n",
      "GROUP BY u.gender, u.level\n",
      "ORDER BY user_count DESC;\n",
      "\n",
      "The user_demographics_query selects the count of users by gender and level (paid or free): \n",
      "\n",
      "(user gender, subscription level, number of such users): \n",
      "\n",
      "('M', 'free', 22)\n",
      "('F', 'free', 21)\n",
      "('F', 'paid', 14)\n",
      "('M', 'paid', 6)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Project 2: Data Warehouse\n"
     ]
    }
   ],
   "source": [
    "print(\"Completed Project 2: Data Warehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
